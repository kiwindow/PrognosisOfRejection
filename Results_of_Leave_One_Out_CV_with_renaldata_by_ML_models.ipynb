{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Results of Leave One Out CV with renaldata by ML models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12XKOSJpbuuZ3dg9bWMopqVWzTQ7sYOgf",
      "authorship_tag": "ABX9TyNxjT21+cQz/00uJQMFB8+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiwindow/PrognosisOfRejection/blob/master/Results_of_Leave_One_Out_CV_with_renaldata_by_ML_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDuRoU5GXU0p",
        "colab_type": "text"
      },
      "source": [
        "#1 System Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czOpSYtHXsmr",
        "colab_type": "text"
      },
      "source": [
        "## 1) Mount this file on Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9OWkXJ4XOSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34945bdc-2ec0-4689-a304-48a89e3ded2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd3LYesNXolS",
        "colab_type": "text"
      },
      "source": [
        "## 2) Data preparation : [Important]  Change the pass for renaldata.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBi4lQ5TXZX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a03323e-5ea6-4c46-aa4c-84a586c37bd6"
      },
      "source": [
        "# Loading modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# Change the pass: 'drive/My Drive/program/data/renaldata.clsv' to a new pass where renaldata.csv is located in your enviromnent \n",
        "df = pd.read_csv('drive/My Drive/program/data/renaldata.csv')\n",
        "print('Number of colums and rows')\n",
        "print(df.shape)\n",
        "print()\n",
        "print('Number of empty cells')\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of colums and rows\n",
            "(51, 212)\n",
            "\n",
            "Number of empty cells\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RMale                        0\n",
              "Rage                         0\n",
              "InfectionCount               0\n",
              "FeverOnly                    0\n",
              "Pyrexia                      0\n",
              "Inflammation                 0\n",
              "VirusInfection               0\n",
              "CMV                          0\n",
              "anemia                       0\n",
              "HeartDisease                 0\n",
              "RespiratoryInfection         0\n",
              "UpperRespiratoryInfection    0\n",
              "UpperDigestivetract          0\n",
              "Diarrhea                     0\n",
              "UTI                          0\n",
              "WBCinUrine                   0\n",
              "WBCpeakover10                0\n",
              "urology                      0\n",
              "Skin                         0\n",
              "WoundInfection               0\n",
              "HerpesZoster                 0\n",
              "Orthopedics                  0\n",
              "Ascites                      0\n",
              "Surgery                      0\n",
              "AerobicGPC                   0\n",
              "AerobicGNR                   0\n",
              "candida                      0\n",
              "staphylococcusaureus         0\n",
              "streptococcusaureus          0\n",
              "enterobacteraerogenes        0\n",
              "enterobactereclacue          0\n",
              "enterococcusfaecalis         0\n",
              "citobacterdiversus           0\n",
              "pseudomonas                  0\n",
              "inflammationdatefirst        0\n",
              "infectiondatelast            0\n",
              "asthma                       0\n",
              "pastanemia                   0\n",
              "infarctionhemohorrage        0\n",
              "calcification                0\n",
              "digestiveorgan               0\n",
              "appendicitis                 0\n",
              "polyp                        0\n",
              "ulcer                        0\n",
              "GERD                         0\n",
              "pastheart                    0\n",
              "kidney                       0\n",
              "pastliverbilialy             0\n",
              "HBV                          0\n",
              "HCV                          0\n",
              "stone                        0\n",
              "hypothyroidism               0\n",
              "gynecology                   0\n",
              "ocular                       0\n",
              "allergy                      0\n",
              "hypertention                 0\n",
              "type2DM                      0\n",
              "BTF                          1\n",
              "timeoftransplantation        0\n",
              "Regraft                      0\n",
              "ABOI                         0\n",
              "HLAABmm                      0\n",
              "HLADRmm                      0\n",
              "HLAmm                        0\n",
              "PRAclass1pre                 0\n",
              "PRAclass2pre                 0\n",
              "PRAclass1after               0\n",
              "PRAclass2after               0\n",
              "MFImax                       0\n",
              "twinpeak                     1\n",
              "DSAclass1                    0\n",
              "DSAclass1number              1\n",
              "DSAclass2                    0\n",
              "DSAclass2number              0\n",
              "preDSA                       1\n",
              "denovoDSA                    1\n",
              "antiHLAclass1                0\n",
              "HSAclass1number              0\n",
              "antiHLAclass2                0\n",
              "HSAclass2number              0\n",
              "denovoDSAandHSAclass2        0\n",
              "denovoDSAandHSAclass1        0\n",
              "preformedDSAandHLAclass2     0\n",
              "preformedDSAandHLAclass1     0\n",
              "A23                          0\n",
              "A25                          0\n",
              "A26                          0\n",
              "A32                          0\n",
              "A34                          0\n",
              "A66                          0\n",
              "B13                          0\n",
              "B18                          0\n",
              "B27                          0\n",
              "B35                          0\n",
              "B37                          0\n",
              "B38                          0\n",
              "B42                          0\n",
              "B44                          0\n",
              "B45                          0\n",
              "B47                          0\n",
              "B49                          0\n",
              "B50                          0\n",
              "B51                          0\n",
              "B52                          0\n",
              "B53                          0\n",
              "B54                          0\n",
              "B55                          0\n",
              "B56                          0\n",
              "B57                          0\n",
              "B58                          0\n",
              "B59                          0\n",
              "B61                          0\n",
              "B62                          0\n",
              "B63                          0\n",
              "B7                           0\n",
              "B71                          0\n",
              "B73                          0\n",
              "B75                          0\n",
              "B77                          0\n",
              "B78                          0\n",
              "B8                           0\n",
              "B82                          0\n",
              "Cw17                         0\n",
              "Cw6                          0\n",
              "Cw9                          0\n",
              "DP10                         0\n",
              "DP11                         0\n",
              "DP13                         0\n",
              "DP14                         0\n",
              "DP15                         0\n",
              "DP17                         0\n",
              "DP18                         0\n",
              "DP19                         0\n",
              "DP20                         0\n",
              "DP3                          0\n",
              "DP4                          0\n",
              "DP5                          0\n",
              "DP6                          0\n",
              "DP9                          0\n",
              "DQ11                         0\n",
              "DQ2                          0\n",
              "DQ4                          0\n",
              "DQ5                          0\n",
              "DQ6                          0\n",
              "DQ7                          0\n",
              "DQ8                          0\n",
              "DQ9                          0\n",
              "DR1                          0\n",
              "DR10                         0\n",
              "DR103                        0\n",
              "DR11                         0\n",
              "DR12                         0\n",
              "DR13                         0\n",
              "DR14                         0\n",
              "DR15                         0\n",
              "DR16                         0\n",
              "DR17                         0\n",
              "DR18                         0\n",
              "DR4                          0\n",
              "DR51                         0\n",
              "DR52                         0\n",
              "DR53                         0\n",
              "DR7                          0\n",
              "DR8                          0\n",
              "DR9                          0\n",
              "pregnancyhistory             0\n",
              "birthhistory                 0\n",
              "NaturalAbortion              0\n",
              "ArtificialAbortion           0\n",
              "HDperiod                     0\n",
              "CGN                          0\n",
              "IgA                          0\n",
              "NS                           0\n",
              "hypoplastickidney            0\n",
              "MalignantHypertention        0\n",
              "Banfi                        0\n",
              "Banfｔ                        0\n",
              "Banfｇ                        0\n",
              "Banfｖ                        0\n",
              "Banfci                       0\n",
              "Banfct                       0\n",
              "Banfcv                       0\n",
              "Banfcg                       0\n",
              "Banfptc                      0\n",
              "Banfptcbm                    0\n",
              "Banfah                       0\n",
              "Banfaah                      0\n",
              "InterstitialHemorrhage       0\n",
              "CellInvasion                 0\n",
              "lymphinvasion                0\n",
              "thrombusformation            0\n",
              "coaglationnecrosis           0\n",
              "IgA.1                        0\n",
              "IgM                          0\n",
              "IgG                          0\n",
              "SABC1q                       0\n",
              "C3                           0\n",
              "C4d                          0\n",
              "C5b                          0\n",
              "bulbarsclerosis              0\n",
              "CRPpreRej                    0\n",
              "CRPpostRej                   0\n",
              "WBCpeakover5                 0\n",
              "MaxCRP                       0\n",
              "WBCpreRej                    0\n",
              "WBCpostKTx                   0\n",
              "WBCpeakover9postRej          0\n",
              "MaxWBC                       0\n",
              "MMFpostRej                   0\n",
              "MMFatRej                     7\n",
              "CNIpostRej                   2\n",
              "GraftLoss                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Xu8HzxaE4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce722810-d371-4e36-d4b8-7e8e0b7bda16"
      },
      "source": [
        "# Interpolation of missing data   　df2: pandas data、    data: numpy data\n",
        "df2 = df.fillna(df.median())\n",
        "data = df2.values\n",
        "\n",
        "df2.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RMale                        0\n",
              "Rage                         0\n",
              "InfectionCount               0\n",
              "FeverOnly                    0\n",
              "Pyrexia                      0\n",
              "Inflammation                 0\n",
              "VirusInfection               0\n",
              "CMV                          0\n",
              "anemia                       0\n",
              "HeartDisease                 0\n",
              "RespiratoryInfection         0\n",
              "UpperRespiratoryInfection    0\n",
              "UpperDigestivetract          0\n",
              "Diarrhea                     0\n",
              "UTI                          0\n",
              "WBCinUrine                   0\n",
              "WBCpeakover10                0\n",
              "urology                      0\n",
              "Skin                         0\n",
              "WoundInfection               0\n",
              "HerpesZoster                 0\n",
              "Orthopedics                  0\n",
              "Ascites                      0\n",
              "Surgery                      0\n",
              "AerobicGPC                   0\n",
              "AerobicGNR                   0\n",
              "candida                      0\n",
              "staphylococcusaureus         0\n",
              "streptococcusaureus          0\n",
              "enterobacteraerogenes        0\n",
              "enterobactereclacue          0\n",
              "enterococcusfaecalis         0\n",
              "citobacterdiversus           0\n",
              "pseudomonas                  0\n",
              "inflammationdatefirst        0\n",
              "infectiondatelast            0\n",
              "asthma                       0\n",
              "pastanemia                   0\n",
              "infarctionhemohorrage        0\n",
              "calcification                0\n",
              "digestiveorgan               0\n",
              "appendicitis                 0\n",
              "polyp                        0\n",
              "ulcer                        0\n",
              "GERD                         0\n",
              "pastheart                    0\n",
              "kidney                       0\n",
              "pastliverbilialy             0\n",
              "HBV                          0\n",
              "HCV                          0\n",
              "stone                        0\n",
              "hypothyroidism               0\n",
              "gynecology                   0\n",
              "ocular                       0\n",
              "allergy                      0\n",
              "hypertention                 0\n",
              "type2DM                      0\n",
              "BTF                          0\n",
              "timeoftransplantation        0\n",
              "Regraft                      0\n",
              "ABOI                         0\n",
              "HLAABmm                      0\n",
              "HLADRmm                      0\n",
              "HLAmm                        0\n",
              "PRAclass1pre                 0\n",
              "PRAclass2pre                 0\n",
              "PRAclass1after               0\n",
              "PRAclass2after               0\n",
              "MFImax                       0\n",
              "twinpeak                     0\n",
              "DSAclass1                    0\n",
              "DSAclass1number              0\n",
              "DSAclass2                    0\n",
              "DSAclass2number              0\n",
              "preDSA                       0\n",
              "denovoDSA                    0\n",
              "antiHLAclass1                0\n",
              "HSAclass1number              0\n",
              "antiHLAclass2                0\n",
              "HSAclass2number              0\n",
              "denovoDSAandHSAclass2        0\n",
              "denovoDSAandHSAclass1        0\n",
              "preformedDSAandHLAclass2     0\n",
              "preformedDSAandHLAclass1     0\n",
              "A23                          0\n",
              "A25                          0\n",
              "A26                          0\n",
              "A32                          0\n",
              "A34                          0\n",
              "A66                          0\n",
              "B13                          0\n",
              "B18                          0\n",
              "B27                          0\n",
              "B35                          0\n",
              "B37                          0\n",
              "B38                          0\n",
              "B42                          0\n",
              "B44                          0\n",
              "B45                          0\n",
              "B47                          0\n",
              "B49                          0\n",
              "B50                          0\n",
              "B51                          0\n",
              "B52                          0\n",
              "B53                          0\n",
              "B54                          0\n",
              "B55                          0\n",
              "B56                          0\n",
              "B57                          0\n",
              "B58                          0\n",
              "B59                          0\n",
              "B61                          0\n",
              "B62                          0\n",
              "B63                          0\n",
              "B7                           0\n",
              "B71                          0\n",
              "B73                          0\n",
              "B75                          0\n",
              "B77                          0\n",
              "B78                          0\n",
              "B8                           0\n",
              "B82                          0\n",
              "Cw17                         0\n",
              "Cw6                          0\n",
              "Cw9                          0\n",
              "DP10                         0\n",
              "DP11                         0\n",
              "DP13                         0\n",
              "DP14                         0\n",
              "DP15                         0\n",
              "DP17                         0\n",
              "DP18                         0\n",
              "DP19                         0\n",
              "DP20                         0\n",
              "DP3                          0\n",
              "DP4                          0\n",
              "DP5                          0\n",
              "DP6                          0\n",
              "DP9                          0\n",
              "DQ11                         0\n",
              "DQ2                          0\n",
              "DQ4                          0\n",
              "DQ5                          0\n",
              "DQ6                          0\n",
              "DQ7                          0\n",
              "DQ8                          0\n",
              "DQ9                          0\n",
              "DR1                          0\n",
              "DR10                         0\n",
              "DR103                        0\n",
              "DR11                         0\n",
              "DR12                         0\n",
              "DR13                         0\n",
              "DR14                         0\n",
              "DR15                         0\n",
              "DR16                         0\n",
              "DR17                         0\n",
              "DR18                         0\n",
              "DR4                          0\n",
              "DR51                         0\n",
              "DR52                         0\n",
              "DR53                         0\n",
              "DR7                          0\n",
              "DR8                          0\n",
              "DR9                          0\n",
              "pregnancyhistory             0\n",
              "birthhistory                 0\n",
              "NaturalAbortion              0\n",
              "ArtificialAbortion           0\n",
              "HDperiod                     0\n",
              "CGN                          0\n",
              "IgA                          0\n",
              "NS                           0\n",
              "hypoplastickidney            0\n",
              "MalignantHypertention        0\n",
              "Banfi                        0\n",
              "Banfｔ                        0\n",
              "Banfｇ                        0\n",
              "Banfｖ                        0\n",
              "Banfci                       0\n",
              "Banfct                       0\n",
              "Banfcv                       0\n",
              "Banfcg                       0\n",
              "Banfptc                      0\n",
              "Banfptcbm                    0\n",
              "Banfah                       0\n",
              "Banfaah                      0\n",
              "InterstitialHemorrhage       0\n",
              "CellInvasion                 0\n",
              "lymphinvasion                0\n",
              "thrombusformation            0\n",
              "coaglationnecrosis           0\n",
              "IgA.1                        0\n",
              "IgM                          0\n",
              "IgG                          0\n",
              "SABC1q                       0\n",
              "C3                           0\n",
              "C4d                          0\n",
              "C5b                          0\n",
              "bulbarsclerosis              0\n",
              "CRPpreRej                    0\n",
              "CRPpostRej                   0\n",
              "WBCpeakover5                 0\n",
              "MaxCRP                       0\n",
              "WBCpreRej                    0\n",
              "WBCpostKTx                   0\n",
              "WBCpeakover9postRej          0\n",
              "MaxWBC                       0\n",
              "MMFpostRej                   0\n",
              "MMFatRej                     0\n",
              "CNIpostRej                   0\n",
              "GraftLoss                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uLtuvrgN00S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dividing explanatory variables and target variable\n",
        "x = df2.iloc[:, :-1].values\n",
        "t = df2.iloc[:, -1].values\n",
        "\n",
        "# splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.3, random_state=0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oloSPaZ1cD5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "356e226e-776b-424e-da6a-4479f154c26e"
      },
      "source": [
        "# Size of dataset\n",
        "print('Number of columns and rows')\n",
        "print(df2.shape)\n",
        "print()\n",
        "print(data)\n",
        "df2.head()\n",
        "# Distribution of target\n",
        "print()\n",
        "print('Distribution of target value')\n",
        "sns.distplot(df2.iloc[:,-1].dropna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of columns and rows\n",
            "(51, 212)\n",
            "\n",
            "[[ 0.         37.          4.         ...  1.05       -0.48152822\n",
            "   0.        ]\n",
            " [ 1.         66.          7.         ...  2.01       -0.46278072\n",
            "   1.        ]\n",
            " [ 1.         62.          1.         ...  5.5        -0.69825448\n",
            "   0.        ]\n",
            " ...\n",
            " [ 1.         29.          4.         ...  2.035       0.58015829\n",
            "   0.        ]\n",
            " [ 1.         50.          1.         ...  2.035       0.53039126\n",
            "   0.        ]\n",
            " [ 0.         45.          3.         ...  0.56        0.11566602\n",
            "   0.        ]]\n",
            "\n",
            "Distribution of target value\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa2e9c856a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1pckzWuuOA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0431f8fd-511b-4556-e14d-ab06520ecd83"
      },
      "source": [
        "df2.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51 entries, 0 to 50\n",
            "Columns: 212 entries, RMale to GraftLoss\n",
            "dtypes: float64(23), int64(189)\n",
            "memory usage: 84.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooASPGa_ubSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "06634f65-425a-4a61-a084-e90c7f3cb83e"
      },
      "source": [
        "df2.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMale</th>\n",
              "      <th>Rage</th>\n",
              "      <th>InfectionCount</th>\n",
              "      <th>FeverOnly</th>\n",
              "      <th>Pyrexia</th>\n",
              "      <th>Inflammation</th>\n",
              "      <th>VirusInfection</th>\n",
              "      <th>CMV</th>\n",
              "      <th>anemia</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>RespiratoryInfection</th>\n",
              "      <th>UpperRespiratoryInfection</th>\n",
              "      <th>UpperDigestivetract</th>\n",
              "      <th>Diarrhea</th>\n",
              "      <th>UTI</th>\n",
              "      <th>WBCinUrine</th>\n",
              "      <th>WBCpeakover10</th>\n",
              "      <th>urology</th>\n",
              "      <th>Skin</th>\n",
              "      <th>WoundInfection</th>\n",
              "      <th>HerpesZoster</th>\n",
              "      <th>Orthopedics</th>\n",
              "      <th>Ascites</th>\n",
              "      <th>Surgery</th>\n",
              "      <th>AerobicGPC</th>\n",
              "      <th>AerobicGNR</th>\n",
              "      <th>candida</th>\n",
              "      <th>staphylococcusaureus</th>\n",
              "      <th>streptococcusaureus</th>\n",
              "      <th>enterobacteraerogenes</th>\n",
              "      <th>enterobactereclacue</th>\n",
              "      <th>enterococcusfaecalis</th>\n",
              "      <th>citobacterdiversus</th>\n",
              "      <th>pseudomonas</th>\n",
              "      <th>inflammationdatefirst</th>\n",
              "      <th>infectiondatelast</th>\n",
              "      <th>asthma</th>\n",
              "      <th>pastanemia</th>\n",
              "      <th>infarctionhemohorrage</th>\n",
              "      <th>calcification</th>\n",
              "      <th>...</th>\n",
              "      <th>NS</th>\n",
              "      <th>hypoplastickidney</th>\n",
              "      <th>MalignantHypertention</th>\n",
              "      <th>Banfi</th>\n",
              "      <th>Banfｔ</th>\n",
              "      <th>Banfｇ</th>\n",
              "      <th>Banfｖ</th>\n",
              "      <th>Banfci</th>\n",
              "      <th>Banfct</th>\n",
              "      <th>Banfcv</th>\n",
              "      <th>Banfcg</th>\n",
              "      <th>Banfptc</th>\n",
              "      <th>Banfptcbm</th>\n",
              "      <th>Banfah</th>\n",
              "      <th>Banfaah</th>\n",
              "      <th>InterstitialHemorrhage</th>\n",
              "      <th>CellInvasion</th>\n",
              "      <th>lymphinvasion</th>\n",
              "      <th>thrombusformation</th>\n",
              "      <th>coaglationnecrosis</th>\n",
              "      <th>IgA.1</th>\n",
              "      <th>IgM</th>\n",
              "      <th>IgG</th>\n",
              "      <th>SABC1q</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4d</th>\n",
              "      <th>C5b</th>\n",
              "      <th>bulbarsclerosis</th>\n",
              "      <th>CRPpreRej</th>\n",
              "      <th>CRPpostRej</th>\n",
              "      <th>WBCpeakover5</th>\n",
              "      <th>MaxCRP</th>\n",
              "      <th>WBCpreRej</th>\n",
              "      <th>WBCpostKTx</th>\n",
              "      <th>WBCpeakover9postRej</th>\n",
              "      <th>MaxWBC</th>\n",
              "      <th>MMFpostRej</th>\n",
              "      <th>MMFatRej</th>\n",
              "      <th>CNIpostRej</th>\n",
              "      <th>GraftLoss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.00000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>51.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>46.666667</td>\n",
              "      <td>4.843137</td>\n",
              "      <td>0.54902</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.431373</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>2.392157</td>\n",
              "      <td>7.772784</td>\n",
              "      <td>2.352941</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>6.274510</td>\n",
              "      <td>171.039216</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>1.254902</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.980392</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>1.117647</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>1.156863</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.412275</td>\n",
              "      <td>0.660075</td>\n",
              "      <td>2.705882</td>\n",
              "      <td>4.573725</td>\n",
              "      <td>0.822844</td>\n",
              "      <td>6.420745</td>\n",
              "      <td>20.901961</td>\n",
              "      <td>13.805294</td>\n",
              "      <td>2.867222</td>\n",
              "      <td>2.469706</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>0.215686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.476095</td>\n",
              "      <td>12.349359</td>\n",
              "      <td>3.258052</td>\n",
              "      <td>0.75667</td>\n",
              "      <td>0.381945</td>\n",
              "      <td>0.325396</td>\n",
              "      <td>0.504878</td>\n",
              "      <td>0.493089</td>\n",
              "      <td>0.500196</td>\n",
              "      <td>0.367290</td>\n",
              "      <td>0.415390</td>\n",
              "      <td>0.428403</td>\n",
              "      <td>0.400979</td>\n",
              "      <td>0.504878</td>\n",
              "      <td>2.173278</td>\n",
              "      <td>2.970686</td>\n",
              "      <td>2.037877</td>\n",
              "      <td>0.325396</td>\n",
              "      <td>0.300327</td>\n",
              "      <td>0.347540</td>\n",
              "      <td>0.271524</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.385013</td>\n",
              "      <td>0.483452</td>\n",
              "      <td>0.488294</td>\n",
              "      <td>0.482640</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.488294</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.271524</td>\n",
              "      <td>0.271524</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.440143</td>\n",
              "      <td>7.189099</td>\n",
              "      <td>235.087385</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.415390</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325396</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>1.055332</td>\n",
              "      <td>0.941838</td>\n",
              "      <td>0.725988</td>\n",
              "      <td>0.691687</td>\n",
              "      <td>0.691687</td>\n",
              "      <td>0.860005</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.972565</td>\n",
              "      <td>0.477740</td>\n",
              "      <td>0.731370</td>\n",
              "      <td>0.360827</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.857264</td>\n",
              "      <td>0.801958</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.196039</td>\n",
              "      <td>0.347540</td>\n",
              "      <td>0.415390</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.385013</td>\n",
              "      <td>0.271524</td>\n",
              "      <td>0.522438</td>\n",
              "      <td>0.237635</td>\n",
              "      <td>0.347540</td>\n",
              "      <td>0.753385</td>\n",
              "      <td>0.862803</td>\n",
              "      <td>6.546126</td>\n",
              "      <td>5.165955</td>\n",
              "      <td>0.942283</td>\n",
              "      <td>1.688243</td>\n",
              "      <td>26.501513</td>\n",
              "      <td>6.360069</td>\n",
              "      <td>1.479068</td>\n",
              "      <td>1.550337</td>\n",
              "      <td>1.286997</td>\n",
              "      <td>0.415390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.542000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.076000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.040000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>-0.947254</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.697000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.207450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>0.131400</td>\n",
              "      <td>5.598000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.845000</td>\n",
              "      <td>2.079464</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>-0.510361</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.138000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081400</td>\n",
              "      <td>0.371900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>0.443500</td>\n",
              "      <td>6.031000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.140000</td>\n",
              "      <td>2.574118</td>\n",
              "      <td>2.035000</td>\n",
              "      <td>-0.216114</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>9.573500</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.395350</td>\n",
              "      <td>0.691850</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.805000</td>\n",
              "      <td>1.136500</td>\n",
              "      <td>7.227500</td>\n",
              "      <td>23.500000</td>\n",
              "      <td>15.750000</td>\n",
              "      <td>3.135159</td>\n",
              "      <td>2.895000</td>\n",
              "      <td>0.107372</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.410000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>909.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.214000</td>\n",
              "      <td>4.797000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>18.140000</td>\n",
              "      <td>3.429000</td>\n",
              "      <td>11.420000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>10.820000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>7.941230</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 212 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           RMale       Rage  InfectionCount  ...   MMFatRej  CNIpostRej  GraftLoss\n",
              "count  51.000000  51.000000       51.000000  ...  51.000000   51.000000  51.000000\n",
              "mean    0.666667  46.666667        4.843137  ...   2.469706    0.030782   0.215686\n",
              "std     0.476095  12.349359        3.258052  ...   1.550337    1.286997   0.415390\n",
              "min     0.000000  21.000000        1.000000  ...   0.540000   -0.947254   0.000000\n",
              "25%     0.000000  36.000000        3.000000  ...   1.500000   -0.510361   0.000000\n",
              "50%     1.000000  47.000000        4.000000  ...   2.035000   -0.216114   0.000000\n",
              "75%     1.000000  56.500000        7.000000  ...   2.895000    0.107372   0.000000\n",
              "max     1.000000  66.000000       12.000000  ...   6.900000    7.941230   1.000000\n",
              "\n",
              "[8 rows x 212 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_zxi3imc1pu",
        "colab_type": "text"
      },
      "source": [
        "## 3) Installation of Optuna and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU82o_cBc404",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c86ddb9-f21d-481e-e4e0-f9dd71ad0a09"
      },
      "source": [
        "# Installation of Optuna\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/b1/a5f0574fa0d769bf0a5629722c84bb0af015967191a37401fe8508c5fb6a/optuna-2.1.0.tar.gz (232kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 4.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.19)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/03/5d15a78ca92ac2bf09f466c54c48bb92979dfe19add2dfed415133ba9792/cmaes-0.6.1-py3-none-any.whl\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.7MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/a3/d439f338aa90edd5ad9096cd56564b44882182150e92148eb14ceb7488ba/pbr-5.5.0-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 14.8MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/28/0d604c8ccbf2d677d3d2c8025724cfa60f10496c0e417e0ab5a22d23c869/cmd2-1.3.10-py3-none-any.whl (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a1/004f04ba411a8002b02aadb089fd6868116c12ddc9f6d576175e89d07587/stevedore-3.2.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (50.3.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.1.0-cp36-none-any.whl size=321090 sha256=c0504c895410e56740b4b4dda5d4f24e2700a1340d06e1391777a89182a15d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/25/24/a165483933b5eefbf4f93c85f3188dc696cbb38620b73ad713\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=e7b553fae2875673e98b458a3470fc475033f60cf3f5b44ff44f29b465ce6c59\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, cmaes, pbr, pyperclip, colorama, cmd2, stevedore, cliff, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.3 cliff-3.4.0 cmaes-0.6.1 cmd2-1.3.10 colorama-0.4.3 colorlog-4.2.1 optuna-2.1.0 pbr-5.5.0 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKE8Uk1wh6wN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c891ca80-d240-4cd1-d106-20890790a7e5"
      },
      "source": [
        "# Installation of XGBoost\n",
        "!pip3 install xgboost\n",
        "!pip3 install -q pydot\n",
        "!pip3 install graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbzmUjC4hJKs",
        "colab_type": "text"
      },
      "source": [
        "# 2. Leave-One-Out cross validation with machine learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_4de0m5sZp-",
        "colab_type": "text"
      },
      "source": [
        "## 1) Simple Linear Regression ; ACU 0.498"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N-TObivfV6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LinearRegression()\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat =  [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Simple Linear Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WOb2F25lDSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "47007a8d-449d-4138-f075-bb35026fe510"
      },
      "source": [
        "linear()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Simple Linear Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.49773   Accuracy: 0.62745   R2: -2.04515\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3            11\n",
            "Predict False            8            29\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49772727272727274, 0.6274509803921569, 0.21428571428571427,\n",
              "       0.2727272727272727, 0.24, 0.725, list([[3, 11], [8, 29]]),\n",
              "       -2.04515491157451], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBIUot2Vsf9D",
        "colab_type": "text"
      },
      "source": [
        "## 2) Lasso Regression ; AUC 0.734"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UObd6dfFlEkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lasso(a):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Lasso\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Lasso(alpha=a)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        \t# Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, confmat, r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Lasso Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBCowdqxuio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "594a0300-f8c1-4119-c3bd-25966a4a2641"
      },
      "source": [
        "lasso(0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Lasso Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.66591   Accuracy: 0.72549   R2: -0.19725\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             2             5\n",
            "Predict False            9            35\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.665909090909091, 0.7254901960784313, 0.2857142857142857,\n",
              "       0.18181818181818182, 0.2222222222222222, 0.875,\n",
              "       list([[2, 5], [9, 35]]), -0.19725016235878678], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpzmPjJs2ZH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9dfa20ae-bc8a-4d1b-dc3f-8fd45ee890a5"
      },
      "source": [
        "lasso(0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Lasso Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.69318   Accuracy: 0.66667   R2: -0.72191\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             4            10\n",
            "Predict False            7            30\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6931818181818181, 0.6666666666666666, 0.2857142857142857,\n",
              "       0.36363636363636365, 0.32, 0.75, list([[4, 10], [7, 30]]),\n",
              "       -0.7219084222358687], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So03bgCx2gT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c7c5e5f0-e0a2-4f23-b2b9-98d64be2b4fa"
      },
      "source": [
        "lasso(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Lasso Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.43409   Accuracy: 0.76471   R2: -0.06329\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             0             1\n",
            "Predict False           11            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.434090909090909, 0.7647058823529411, 0.0, 0.0, 0.0, 0.975,\n",
              "       list([[0, 1], [11, 39]]), -0.06329137947570573], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IDcKSlf0MUZ",
        "colab_type": "text"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHiZDlIM0V5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lassoOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Lasso\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    alpha = trial.suggest_uniform('alpha', 0.01, 1)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Lasso(alpha=alpha)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "     \n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1 - AUC\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def lassoTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(lassoOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hyper parameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlpRWImh1x1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62cc043b-49df-443e-ec95-780f99e9a931"
      },
      "source": [
        "lassoTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-09-19 09:36:57,374] A new study created in memory with name: no-name-8a3b1555-260d-4b9d-81c8-b6b0f7863917\n",
            "[I 2020-09-19 09:36:57,446] Trial 0 finished with value: 1.7322834645669292 and parameters: {'alpha': 0.5468973635867508}. Best is trial 0 with value: 1.7322834645669292.\n",
            "[I 2020-09-19 09:36:57,522] Trial 1 finished with value: 1.8181818181818181 and parameters: {'alpha': 0.3164828966134761}. Best is trial 0 with value: 1.7322834645669292.\n",
            "[I 2020-09-19 09:36:57,594] Trial 2 finished with value: 1.8410041841004183 and parameters: {'alpha': 0.2863582888630547}. Best is trial 0 with value: 1.7322834645669292.\n",
            "[I 2020-09-19 09:36:57,674] Trial 3 finished with value: 1.685823754789272 and parameters: {'alpha': 0.6339916873793024}. Best is trial 3 with value: 1.685823754789272.\n",
            "[I 2020-09-19 09:36:57,738] Trial 4 finished with value: 1.7054263565891472 and parameters: {'alpha': 0.7962267259138708}. Best is trial 3 with value: 1.685823754789272.\n",
            "[I 2020-09-19 09:36:57,806] Trial 5 finished with value: 1.7886178861788617 and parameters: {'alpha': 0.9279092526335121}. Best is trial 3 with value: 1.685823754789272.\n",
            "[I 2020-09-19 09:36:57,880] Trial 6 finished with value: 1.7600000000000002 and parameters: {'alpha': 0.8849235907263094}. Best is trial 3 with value: 1.685823754789272.\n",
            "[I 2020-09-19 09:36:57,958] Trial 7 finished with value: 1.7391304347826089 and parameters: {'alpha': 0.417398291343736}. Best is trial 3 with value: 1.685823754789272.\n",
            "[I 2020-09-19 09:36:58,114] Trial 8 finished with value: 1.414790996784566 and parameters: {'alpha': 0.0699381241485633}. Best is trial 8 with value: 1.414790996784566.\n",
            "[I 2020-09-19 09:36:58,198] Trial 9 finished with value: 1.752988047808765 and parameters: {'alpha': 0.3788302209126961}. Best is trial 8 with value: 1.414790996784566.\n",
            "[I 2020-09-19 09:36:58,413] Trial 10 finished with value: 1.4102564102564101 and parameters: {'alpha': 0.01580298336902012}. Best is trial 10 with value: 1.4102564102564101.\n",
            "[I 2020-09-19 09:36:58,531] Trial 11 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.05869581248257437}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:58,739] Trial 12 finished with value: 1.4102564102564101 and parameters: {'alpha': 0.015688143198711365}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:58,829] Trial 13 finished with value: 1.6923076923076925 and parameters: {'alpha': 0.1394144993040486}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:58,917] Trial 14 finished with value: 1.71875 and parameters: {'alpha': 0.16037498000763906}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,197] Trial 15 finished with value: 1.4102564102564104 and parameters: {'alpha': 0.012113662316912584}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,284] Trial 16 finished with value: 1.7670682730923695 and parameters: {'alpha': 0.20987889778274932}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,513] Trial 17 finished with value: 1.4193548387096773 and parameters: {'alpha': 0.01382135345707276}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,597] Trial 18 finished with value: 1.8106995884773662 and parameters: {'alpha': 0.21872009577382415}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,675] Trial 19 finished with value: 1.673003802281369 and parameters: {'alpha': 0.7017219717329499}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,771] Trial 20 finished with value: 1.4379084967320261 and parameters: {'alpha': 0.09129684047293109}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:36:59,965] Trial 21 finished with value: 1.414790996784566 and parameters: {'alpha': 0.015335904046128316}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,066] Trial 22 finished with value: 1.4239482200647249 and parameters: {'alpha': 0.08321031166107291}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,198] Trial 23 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.028973694745649363}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,280] Trial 24 finished with value: 1.8565400843881859 and parameters: {'alpha': 0.24116158964313691}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,368] Trial 25 finished with value: 1.673003802281369 and parameters: {'alpha': 0.12796382139306975}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,440] Trial 26 finished with value: 1.7322834645669292 and parameters: {'alpha': 0.4451993548281571}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,516] Trial 27 finished with value: 1.752988047808765 and parameters: {'alpha': 0.3338800403133423}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,606] Trial 28 finished with value: 1.7600000000000002 and parameters: {'alpha': 0.19038686991209153}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,690] Trial 29 finished with value: 1.7322834645669294 and parameters: {'alpha': 0.5217593894252353}. Best is trial 11 with value: 1.4012738853503186.\n",
            "[I 2020-09-19 09:37:00,808] Trial 30 finished with value: 1.38801261829653 and parameters: {'alpha': 0.05000043102696057}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:00,919] Trial 31 finished with value: 1.4057507987220446 and parameters: {'alpha': 0.06358078025661738}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,028] Trial 32 finished with value: 1.423948220064725 and parameters: {'alpha': 0.07855420242715934}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,115] Trial 33 finished with value: 1.8487394957983194 and parameters: {'alpha': 0.2754940352808024}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,208] Trial 34 finished with value: 1.6793893129770991 and parameters: {'alpha': 0.129788829132368}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,280] Trial 35 finished with value: 1.7054263565891472 and parameters: {'alpha': 0.5987456410544998}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,389] Trial 36 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.061142791643547}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,469] Trial 37 finished with value: 1.8644067796610169 and parameters: {'alpha': 0.27041293150894263}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,569] Trial 38 finished with value: 1.71875 and parameters: {'alpha': 0.15750376221763274}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,645] Trial 39 finished with value: 1.7600000000000002 and parameters: {'alpha': 0.3302637445658586}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,762] Trial 40 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.05828904229169433}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,867] Trial 41 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.060919542523375586}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:01,953] Trial 42 finished with value: 1.5827338129496402 and parameters: {'alpha': 0.11856182573744838}. Best is trial 30 with value: 1.38801261829653.\n",
            "[I 2020-09-19 09:37:02,066] Trial 43 finished with value: 1.370716510903427 and parameters: {'alpha': 0.03642667621574977}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,163] Trial 44 finished with value: 1.7322834645669294 and parameters: {'alpha': 0.1699626889034376}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,479] Trial 45 finished with value: 1.414790996784566 and parameters: {'alpha': 0.011602792407860475}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,593] Trial 46 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.05558403019041617}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,698] Trial 47 finished with value: 1.5714285714285714 and parameters: {'alpha': 0.11450103198782796}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,792] Trial 48 finished with value: 1.7600000000000002 and parameters: {'alpha': 0.1896858898781643}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,907] Trial 49 finished with value: 1.3750000000000002 and parameters: {'alpha': 0.04917600441396306}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:02,991] Trial 50 finished with value: 1.8565400843881859 and parameters: {'alpha': 0.2462873072825028}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:03,103] Trial 51 finished with value: 1.370716510903427 and parameters: {'alpha': 0.043945715265744985}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:03,241] Trial 52 finished with value: 1.375 and parameters: {'alpha': 0.03369476493670899}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:03,338] Trial 53 finished with value: 1.456953642384106 and parameters: {'alpha': 0.095314083471463}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:03,571] Trial 54 finished with value: 1.414790996784566 and parameters: {'alpha': 0.013602797296579677}. Best is trial 43 with value: 1.370716510903427.\n",
            "[I 2020-09-19 09:37:03,682] Trial 55 finished with value: 1.3664596273291925 and parameters: {'alpha': 0.03893487770440182}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:03,758] Trial 56 finished with value: 1.6988416988416988 and parameters: {'alpha': 0.7635445155985258}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:03,868] Trial 57 finished with value: 1.375 and parameters: {'alpha': 0.03725837901260439}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:03,954] Trial 58 finished with value: 1.7254901960784312 and parameters: {'alpha': 0.15176837449457234}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,045] Trial 59 finished with value: 1.5492957746478873 and parameters: {'alpha': 0.1098218202002442}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,228] Trial 60 finished with value: 1.4239482200647249 and parameters: {'alpha': 0.016557298000796035}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,343] Trial 61 finished with value: 1.3664596273291925 and parameters: {'alpha': 0.03889500405672913}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,467] Trial 62 finished with value: 1.3793103448275863 and parameters: {'alpha': 0.03251979836861668}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,535] Trial 63 finished with value: 1.8181818181818188 and parameters: {'alpha': 0.957666891654493}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,640] Trial 64 finished with value: 1.4715719063545152 and parameters: {'alpha': 0.09748609538800787}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:04,775] Trial 65 finished with value: 1.375 and parameters: {'alpha': 0.03549396262686037}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:05,029] Trial 66 finished with value: 1.414790996784566 and parameters: {'alpha': 0.013648975026239737}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:05,142] Trial 67 finished with value: 1.4379084967320261 and parameters: {'alpha': 0.09103820433181062}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:05,245] Trial 68 finished with value: 1.7054263565891472 and parameters: {'alpha': 0.1416004358253229}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:05,342] Trial 69 finished with value: 1.746031746031746 and parameters: {'alpha': 0.18463468482244685}. Best is trial 55 with value: 1.3664596273291925.\n",
            "[I 2020-09-19 09:37:05,495] Trial 70 finished with value: 1.3622291021671828 and parameters: {'alpha': 0.041913481574417606}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:05,614] Trial 71 finished with value: 1.3664596273291927 and parameters: {'alpha': 0.042534353034015406}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:05,723] Trial 72 finished with value: 1.4193548387096775 and parameters: {'alpha': 0.07419785262763957}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:05,862] Trial 73 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.031871967935032525}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:05,954] Trial 74 finished with value: 1.6666666666666667 and parameters: {'alpha': 0.1255531436089133}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,282] Trial 75 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.01054190848625932}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,373] Trial 76 finished with value: 1.8106995884773662 and parameters: {'alpha': 0.22212524639880868}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,476] Trial 77 finished with value: 1.4379084967320261 and parameters: {'alpha': 0.08669225541085361}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,607] Trial 78 finished with value: 1.3664596273291927 and parameters: {'alpha': 0.043509313463927016}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,714] Trial 79 finished with value: 1.4193548387096775 and parameters: {'alpha': 0.07560238509810929}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,826] Trial 80 finished with value: 1.7254901960784312 and parameters: {'alpha': 0.1555061451684724}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:06,948] Trial 81 finished with value: 1.3664596273291925 and parameters: {'alpha': 0.0383384218318985}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,076] Trial 82 finished with value: 1.3664596273291927 and parameters: {'alpha': 0.04624863388496574}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,169] Trial 83 finished with value: 1.5438596491228072 and parameters: {'alpha': 0.10823107447737366}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,280] Trial 84 finished with value: 1.4012738853503186 and parameters: {'alpha': 0.05563198974182235}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,347] Trial 85 finished with value: 1.7322834645669292 and parameters: {'alpha': 0.43943800733807536}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,645] Trial 86 finished with value: 1.414790996784566 and parameters: {'alpha': 0.011176676456483275}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,714] Trial 87 finished with value: 1.7529880478087647 and parameters: {'alpha': 0.8593298466992645}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,828] Trial 88 finished with value: 1.4193548387096775 and parameters: {'alpha': 0.07559292460228047}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:07,913] Trial 89 finished with value: 1.673003802281369 and parameters: {'alpha': 0.13066657562603118}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,030] Trial 90 finished with value: 1.3793103448275863 and parameters: {'alpha': 0.04723134178284924}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,141] Trial 91 finished with value: 1.370716510903427 and parameters: {'alpha': 0.036323669312752854}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,235] Trial 92 finished with value: 1.5277777777777777 and parameters: {'alpha': 0.10347908682490842}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,339] Trial 93 finished with value: 1.4193548387096775 and parameters: {'alpha': 0.07368367320766124}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,495] Trial 94 finished with value: 1.38801261829653 and parameters: {'alpha': 0.04991869890213535}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,779] Trial 95 finished with value: 1.4102564102564104 and parameters: {'alpha': 0.012516180288603657}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:08,912] Trial 96 finished with value: 1.3793103448275863 and parameters: {'alpha': 0.03490155629452168}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:09,004] Trial 97 finished with value: 1.746031746031746 and parameters: {'alpha': 0.1747305656751487}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:09,104] Trial 98 finished with value: 1.4379084967320261 and parameters: {'alpha': 0.0878019670850466}. Best is trial 70 with value: 1.3622291021671828.\n",
            "[I 2020-09-19 09:37:09,199] Trial 99 finished with value: 1.685823754789272 and parameters: {'alpha': 0.13782148193563742}. Best is trial 70 with value: 1.3622291021671828.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyper parameter： {'alpha': 0.041913481574417606}\n",
            "AUC： 0.734090909090909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mURvDSugu6fJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c21cc273-d373-4aab-ef7e-a80d1974dd53"
      },
      "source": [
        "# This alpha value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "lasso(0.041913481574417606)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Lasso Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.73409   Accuracy: 0.72549   R2: -0.16791\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3             6\n",
            "Predict False            8            34\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.734090909090909, 0.7254901960784313, 0.3333333333333333,\n",
              "       0.2727272727272727, 0.3, 0.85, list([[3, 6], [8, 34]]),\n",
              "       -0.1679078135148202], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBDb2Ubx_FiQ",
        "colab_type": "text"
      },
      "source": [
        "## 3) Ridge Regression ; AUC 0.632"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUjAy5H3_HzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ridge(a):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Ridge(alpha=a)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, confmat, r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Ridge Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFOzHN0v_ogF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9bbd0f80-30bf-496f-fe1d-ed69c4df9d00"
      },
      "source": [
        "ridge(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.51818   Accuracy: 0.62745   R2: -1.91292\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3            11\n",
            "Predict False            8            29\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5181818181818182, 0.6274509803921569, 0.21428571428571427,\n",
              "       0.2727272727272727, 0.24, 0.725, list([[3, 11], [8, 29]]),\n",
              "       -1.9129247728164027], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9gq1EUP_qaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "084d4d33-c30b-4fe5-eb77-243eecfcf61e"
      },
      "source": [
        "ridge(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.62727   Accuracy: 0.70588   R2: -0.46392\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3             7\n",
            "Predict False            8            33\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6272727272727272, 0.7058823529411765, 0.3, 0.2727272727272727,\n",
              "       0.2857142857142857, 0.825, list([[3, 7], [8, 33]]),\n",
              "       -0.4639196454021983], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFmKxlnZ_sct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2c7e670f-c30b-4eac-b976-9d49493a1893"
      },
      "source": [
        "ridge(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.59091   Accuracy: 0.72549   R2: -0.21508\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             2             5\n",
            "Predict False            9            35\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5909090909090909, 0.7254901960784313, 0.2857142857142857,\n",
              "       0.18181818181818182, 0.2222222222222222, 0.875,\n",
              "       list([[2, 5], [9, 35]]), -0.2150790729071388], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf_erWLk_uH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b184f953-1cb4-4cac-beaf-fddae1764d6d"
      },
      "source": [
        "ridge(0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.5   Accuracy: 0.62745   R2: -2.02895\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3            11\n",
            "Predict False            8            29\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49999999999999994, 0.6274509803921569, 0.21428571428571427,\n",
              "       0.2727272727272727, 0.24, 0.725, list([[3, 11], [8, 29]]),\n",
              "       -2.0289511181637043], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zir3sUM_2W5",
        "colab_type": "text"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI25pyN4_xxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ridgeOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    alpha = trial.suggest_uniform('alpha', 1, 1000)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Ridge(alpha=alpha)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1/AUC　\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def ridgeTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(ridgeOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hpyterparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)\n",
        "    print()\n",
        "    return study.best_params['alpha']    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnCYS4sl4viA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5aae1c2e-5f71-40c0-a008-dc924459812e"
      },
      "source": [
        "ridgeTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-09-19 09:45:37,718] A new study created in memory with name: no-name-a964ed54-ccb5-4261-ae12-0f194c6c19ae\n",
            "[I 2020-09-19 09:45:37,807] Trial 0 finished with value: 1.6541353383458648 and parameters: {'alpha': 502.08382376876386}. Best is trial 0 with value: 1.6541353383458648.\n",
            "[I 2020-09-19 09:45:38,028] Trial 1 finished with value: 1.660377358490566 and parameters: {'alpha': 619.328346700925}. Best is trial 0 with value: 1.6541353383458648.\n",
            "[I 2020-09-19 09:45:38,099] Trial 2 finished with value: 1.6236162361623618 and parameters: {'alpha': 320.54271531147975}. Best is trial 2 with value: 1.6236162361623618.\n",
            "[I 2020-09-19 09:45:38,170] Trial 3 finished with value: 1.8106995884773667 and parameters: {'alpha': 4.673798212382571}. Best is trial 2 with value: 1.6236162361623618.\n",
            "[I 2020-09-19 09:45:38,233] Trial 4 finished with value: 1.6236162361623618 and parameters: {'alpha': 225.60989331247978}. Best is trial 2 with value: 1.6236162361623618.\n",
            "[I 2020-09-19 09:45:38,300] Trial 5 finished with value: 1.6176470588235294 and parameters: {'alpha': 211.23193416128123}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,389] Trial 6 finished with value: 1.660377358490566 and parameters: {'alpha': 573.2863878412443}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,455] Trial 7 finished with value: 1.660377358490566 and parameters: {'alpha': 601.8535689642396}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,518] Trial 8 finished with value: 1.685823754789272 and parameters: {'alpha': 888.9027397426358}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,579] Trial 9 finished with value: 1.685823754789272 and parameters: {'alpha': 898.8927893355691}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,648] Trial 10 finished with value: 1.7054263565891472 and parameters: {'alpha': 14.700773600893115}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,714] Trial 11 finished with value: 1.6236162361623618 and parameters: {'alpha': 288.74950748867013}. Best is trial 5 with value: 1.6176470588235294.\n",
            "[I 2020-09-19 09:45:38,781] Trial 12 finished with value: 1.6176470588235292 and parameters: {'alpha': 253.66021211293764}. Best is trial 12 with value: 1.6176470588235292.\n",
            "[I 2020-09-19 09:45:38,851] Trial 13 finished with value: 1.6296296296296295 and parameters: {'alpha': 166.64586709137822}. Best is trial 12 with value: 1.6176470588235292.\n",
            "[I 2020-09-19 09:45:38,926] Trial 14 finished with value: 1.6356877323420076 and parameters: {'alpha': 393.8477394799787}. Best is trial 12 with value: 1.6176470588235292.\n",
            "[I 2020-09-19 09:45:38,994] Trial 15 finished with value: 1.6356877323420072 and parameters: {'alpha': 176.26439897519035}. Best is trial 12 with value: 1.6176470588235292.\n",
            "[I 2020-09-19 09:45:39,060] Trial 16 finished with value: 1.5942028985507248 and parameters: {'alpha': 97.6567889440346}. Best is trial 16 with value: 1.5942028985507248.\n",
            "[I 2020-09-19 09:45:39,127] Trial 17 finished with value: 1.6117216117216115 and parameters: {'alpha': 49.32759945431692}. Best is trial 16 with value: 1.5942028985507248.\n",
            "[I 2020-09-19 09:45:39,201] Trial 18 finished with value: 1.588447653429603 and parameters: {'alpha': 70.53955737531226}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,267] Trial 19 finished with value: 1.5942028985507248 and parameters: {'alpha': 89.23054095829855}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,336] Trial 20 finished with value: 1.6479400749063673 and parameters: {'alpha': 408.7139909067889}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,417] Trial 21 finished with value: 1.5942028985507248 and parameters: {'alpha': 111.77046786896135}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,484] Trial 22 finished with value: 1.5942028985507248 and parameters: {'alpha': 99.3298020350109}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,550] Trial 23 finished with value: 1.5942028985507248 and parameters: {'alpha': 87.46543395658568}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,621] Trial 24 finished with value: 1.6666666666666667 and parameters: {'alpha': 771.8179828853912}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,700] Trial 25 finished with value: 1.6058394160583942 and parameters: {'alpha': 144.38866265245946}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,770] Trial 26 finished with value: 1.8965517241379313 and parameters: {'alpha': 2.8695791932072865}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,838] Trial 27 finished with value: 1.6236162361623618 and parameters: {'alpha': 312.6880540777735}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,903] Trial 28 finished with value: 1.6356877323420076 and parameters: {'alpha': 381.94223541578117}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:39,971] Trial 29 finished with value: 1.8803418803418805 and parameters: {'alpha': 3.192063251883667}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,035] Trial 30 finished with value: 1.6541353383458648 and parameters: {'alpha': 489.7930069050548}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,099] Trial 31 finished with value: 1.5942028985507246 and parameters: {'alpha': 68.39219009842311}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,170] Trial 32 finished with value: 1.5942028985507246 and parameters: {'alpha': 67.66983309557591}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,238] Trial 33 finished with value: 1.6117216117216115 and parameters: {'alpha': 60.99807139733077}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,304] Trial 34 finished with value: 1.6236162361623618 and parameters: {'alpha': 162.08096589115175}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,383] Trial 35 finished with value: 1.6117216117216115 and parameters: {'alpha': 49.97011886952558}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,451] Trial 36 finished with value: 1.6236162361623618 and parameters: {'alpha': 240.34524296677412}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,518] Trial 37 finished with value: 1.6296296296296295 and parameters: {'alpha': 205.15656134309933}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,585] Trial 38 finished with value: 1.673003802281369 and parameters: {'alpha': 697.3388274567179}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,659] Trial 39 finished with value: 1.5999999999999996 and parameters: {'alpha': 133.85913573829123}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,730] Trial 40 finished with value: 1.6923076923076923 and parameters: {'alpha': 989.6983573227985}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,808] Trial 41 finished with value: 1.6000000000000003 and parameters: {'alpha': 113.98417749222337}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,904] Trial 42 finished with value: 1.7813765182186234 and parameters: {'alpha': 5.6073292479673}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:40,982] Trial 43 finished with value: 1.5942028985507246 and parameters: {'alpha': 66.89241936357244}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,055] Trial 44 finished with value: 1.6117216117216115 and parameters: {'alpha': 53.71987260668536}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,127] Trial 45 finished with value: 1.6176470588235294 and parameters: {'alpha': 209.29862319630593}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,210] Trial 46 finished with value: 1.6236162361623618 and parameters: {'alpha': 274.88911401441385}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,294] Trial 47 finished with value: 1.6356877323420076 and parameters: {'alpha': 35.45388725765309}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,372] Trial 48 finished with value: 1.6417910447761193 and parameters: {'alpha': 188.35901638379738}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,453] Trial 49 finished with value: 1.5942028985507248 and parameters: {'alpha': 79.66365132435199}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,531] Trial 50 finished with value: 1.6236162361623618 and parameters: {'alpha': 163.63124630988162}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,614] Trial 51 finished with value: 1.5999999999999996 and parameters: {'alpha': 119.07208097518517}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,692] Trial 52 finished with value: 1.588447653429603 and parameters: {'alpha': 70.9846244638232}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,777] Trial 53 finished with value: 1.7254901960784317 and parameters: {'alpha': 9.400404414903946}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,854] Trial 54 finished with value: 1.6356877323420076 and parameters: {'alpha': 36.64684183702276}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:41,930] Trial 55 finished with value: 1.5942028985507248 and parameters: {'alpha': 79.55141159545691}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,009] Trial 56 finished with value: 1.6117216117216115 and parameters: {'alpha': 148.74568884666968}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,086] Trial 57 finished with value: 1.5999999999999996 and parameters: {'alpha': 118.17055067747586}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,158] Trial 58 finished with value: 1.6236162361623618 and parameters: {'alpha': 240.13472791574642}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,239] Trial 59 finished with value: 1.6296296296296295 and parameters: {'alpha': 340.3662409456555}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,317] Trial 60 finished with value: 1.6 and parameters: {'alpha': 84.91950929489813}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,417] Trial 61 finished with value: 1.588447653429603 and parameters: {'alpha': 72.02117543350688}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,494] Trial 62 finished with value: 1.647940074906367 and parameters: {'alpha': 32.11969962421211}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,575] Trial 63 finished with value: 1.5942028985507246 and parameters: {'alpha': 68.04948133593533}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,653] Trial 64 finished with value: 1.904761904761905 and parameters: {'alpha': 1.4083581045015734}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,731] Trial 65 finished with value: 1.6176470588235294 and parameters: {'alpha': 56.569815344101684}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,821] Trial 66 finished with value: 1.6356877323420072 and parameters: {'alpha': 180.32306445142933}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,903] Trial 67 finished with value: 1.6058394160583942 and parameters: {'alpha': 142.43662015433648}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:42,982] Trial 68 finished with value: 1.5942028985507248 and parameters: {'alpha': 90.49351052497707}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,068] Trial 69 finished with value: 1.6793893129770991 and parameters: {'alpha': 24.110379337179317}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,148] Trial 70 finished with value: 1.6176470588235294 and parameters: {'alpha': 57.297032504114284}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,222] Trial 71 finished with value: 1.6 and parameters: {'alpha': 102.01882453250784}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,293] Trial 72 finished with value: 1.5942028985507248 and parameters: {'alpha': 77.24510026645001}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,374] Trial 73 finished with value: 1.5999999999999996 and parameters: {'alpha': 130.26533193966517}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,462] Trial 74 finished with value: 1.7813765182186234 and parameters: {'alpha': 6.088226007067249}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,534] Trial 75 finished with value: 1.6417910447761193 and parameters: {'alpha': 197.18702016710074}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,606] Trial 76 finished with value: 1.588447653429603 and parameters: {'alpha': 73.63087786866201}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,682] Trial 77 finished with value: 1.6541353383458648 and parameters: {'alpha': 480.6544731992191}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,758] Trial 78 finished with value: 1.647940074906367 and parameters: {'alpha': 31.68539645262848}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,834] Trial 79 finished with value: 1.6236162361623618 and parameters: {'alpha': 154.84939865824504}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,907] Trial 80 finished with value: 1.588447653429603 and parameters: {'alpha': 70.89895314356173}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:43,988] Trial 81 finished with value: 1.6176470588235294 and parameters: {'alpha': 60.03702244724072}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,062] Trial 82 finished with value: 1.5942028985507248 and parameters: {'alpha': 109.99829628422555}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,135] Trial 83 finished with value: 1.5942028985507246 and parameters: {'alpha': 68.41820997568823}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,208] Trial 84 finished with value: 1.6730038022813687 and parameters: {'alpha': 25.972023243022313}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,280] Trial 85 finished with value: 1.5942028985507248 and parameters: {'alpha': 100.80881534821464}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,356] Trial 86 finished with value: 1.5999999999999996 and parameters: {'alpha': 135.04766771926205}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,451] Trial 87 finished with value: 1.8965517241379313 and parameters: {'alpha': 2.2790000600854086}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,556] Trial 88 finished with value: 1.6356877323420072 and parameters: {'alpha': 179.46692360826006}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,641] Trial 89 finished with value: 1.5942028985507246 and parameters: {'alpha': 67.79161309709357}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,708] Trial 90 finished with value: 1.6117216117216115 and parameters: {'alpha': 48.759728295520205}. Best is trial 18 with value: 1.588447653429603.\n",
            "[I 2020-09-19 09:45:44,779] Trial 91 finished with value: 1.5827338129496402 and parameters: {'alpha': 71.79566461970718}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:44,847] Trial 92 finished with value: 1.588447653429603 and parameters: {'alpha': 98.37679264127507}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:44,917] Trial 93 finished with value: 1.5999999999999996 and parameters: {'alpha': 128.427435113456}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:44,990] Trial 94 finished with value: 1.6793893129770991 and parameters: {'alpha': 24.069693900895324}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:45,061] Trial 95 finished with value: 1.6236162361623618 and parameters: {'alpha': 221.59272207075009}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:45,129] Trial 96 finished with value: 1.5942028985507248 and parameters: {'alpha': 95.11421554206957}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:45,198] Trial 97 finished with value: 1.5999999999999996 and parameters: {'alpha': 118.16221612366098}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:45,269] Trial 98 finished with value: 1.5942028985507248 and parameters: {'alpha': 78.82828121104427}. Best is trial 91 with value: 1.5827338129496402.\n",
            "[I 2020-09-19 09:45:45,339] Trial 99 finished with value: 1.6296296296296295 and parameters: {'alpha': 44.18414032831724}. Best is trial 91 with value: 1.5827338129496402.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hpyterparameter： {'alpha': 71.79566461970718}\n",
            "AUC： 0.6318181818181818\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.79566461970718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfJar0PTwX8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "3b29c49a-a39e-4cfc-dedb-ce40a597c3d2"
      },
      "source": [
        "# This alpha value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "ridge(71.79566461970718)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.63182   Accuracy: 0.72549   R2: -0.54674\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3             6\n",
            "Predict False            8            34\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6318181818181818, 0.7254901960784313, 0.3333333333333333,\n",
              "       0.2727272727272727, 0.3, 0.85, list([[3, 6], [8, 34]]),\n",
              "       -0.5467390446019575], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_PFDJnGnrH",
        "colab_type": "text"
      },
      "source": [
        "## 4) Logistic Regression ; AUC 0.553\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKKZIYvYOeQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling with Normalization using MaxMin\n",
        "\n",
        "def logisticN():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x)\n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2]  )\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Logistic Regression with Normalization')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Scaling with Standardization\n",
        "\n",
        "def logisticS():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = StandardScaler() \n",
        "    scaler.fit(x)  \n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "       \n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        " \n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2]  )\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Logistic Regression with Standardization')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usE_YMhTPTmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "de8dde26-3f4d-4cba-f0c3-f038b8b4e84e"
      },
      "source": [
        "logisticN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Logistic Regression with Normalization\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.55341   Accuracy: 0.76471   R2: -0.39091\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             2             3\n",
            "Predict False            9            37\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.553409090909091, 0.7647058823529411, 0.4, 0.18181818181818182,\n",
              "       0.25, 0.925, list([[2, 3], [9, 37]]), -0.3909090909090913],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzOgSfrtPWAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fb0b1366-551d-43d2-fd88-6b43338c5cdc"
      },
      "source": [
        "logisticS()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Logistic Regression with Standardization\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.52045   Accuracy: 0.76471   R2: -0.39091\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             2\n",
            "Predict False           10            38\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5204545454545454, 0.7647058823529411, 0.3333333333333333,\n",
              "       0.09090909090909091, 0.14285714285714285, 0.95,\n",
              "       list([[1, 2], [10, 38]]), -0.3909090909090913], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15XXh2sJGv3s",
        "colab_type": "text"
      },
      "source": [
        "## 5) Support Vector Machine ; AUC 0.500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Z9ztLKQnpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "\n",
        "def SVMn():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x)\n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    svm = SVC()\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        svm.fit(x_train, t_train)\n",
        "        result = svm.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Support Vector Machine with Normalizatioin')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "# Standardization\n",
        "\n",
        "def SVMs():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score    \n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = StandardScaler() \n",
        "    scaler.fit(x)  \n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    svm = SVC()\n",
        "\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        svm.fit(x_train, t_train)\n",
        "        result = svm.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "  \n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Support Vector Machine with Standardizatioin')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg6EaiGoQ98P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bf690d33-ea5a-45b9-e77d-0783213d6f1b"
      },
      "source": [
        "SVMn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Support Vector Machine with Normalizatioin\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.5   Accuracy: 0.78431   R2: -0.275\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             0             0\n",
            "Predict False           11            40\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.7843137254901961, 'N/A', 0.0, 0.0, 1.0,\n",
              "       list([[0, 0], [11, 40]]), -0.27500000000000036], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhd8LEYJRDz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c732da38-9a9c-4a92-e705-45f4e91ae251"
      },
      "source": [
        "SVMs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Support Vector Machine with Standardizatioin\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.5   Accuracy: 0.78431   R2: -0.275\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             0             0\n",
            "Predict False           11            40\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.7843137254901961, 'N/A', 0.0, 0.0, 1.0,\n",
              "       list([[0, 0], [11, 40]]), -0.27500000000000036], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV7FvV2zGzo-",
        "colab_type": "text"
      },
      "source": [
        "## 6) Random Forest ; AUC 0.545"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abt5RB5PRT5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomF(random_state):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state=random_state)\n",
        "  \n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Random Forest')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "#    from pprint import pprint\n",
        "#    print('◆ The defalut settings of the hyperparameters')\n",
        "#    pprint(rf.get_params())  \n",
        "    # n_estimators, max_features should be optimized first\n",
        "    # then, max_depth, min_sample_split, min_samples_leaf, bootstrap\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npYLYgM-SE2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "98f3ddfb-3442-488e-9a1a-bf11a366b28d"
      },
      "source": [
        "randomF(1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.53295   Accuracy: 0.78431   R2: -0.275\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             1\n",
            "Predict False           10            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5329545454545453, 0.7843137254901961, 0.5, 0.09090909090909091,\n",
              "       0.15384615384615385, 0.975, list([[1, 1], [10, 39]]),\n",
              "       -0.27500000000000036], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YirI1_ICkSf9",
        "colab_type": "text"
      },
      "source": [
        "### Optimization with RandomizedSearchCV & GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeNHMUEQncIa",
        "colab_type": "text"
      },
      "source": [
        "#### A. RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNEspFAES4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomSearch(variables, label):\n",
        "    from sklearn.model_selection import RandomizedSearchCV\n",
        "    from pprint import pprint\n",
        "\n",
        "    # Number of trees in random forest\n",
        "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "    # Number of features to consider at every split\n",
        "    max_features = ['auto', 'sqrt']\n",
        "    # Maximum number of levels in tree\n",
        "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "    max_depth.append(None)\n",
        "    # Minimum number of samples required to split a node\n",
        "    min_samples_split = [2, 5, 10]\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    min_samples_leaf = [1, 2, 4]\n",
        "    # Method of selecting samples for training each tree\n",
        "    bootstrap = [True, False]\n",
        "\n",
        "    # Create the random grid\n",
        "    random_grid = {'n_estimators': n_estimators,\n",
        "                  'max_features': max_features,\n",
        "                  'max_depth': max_depth,\n",
        "                  'min_samples_split': min_samples_split,\n",
        "                  'min_samples_leaf': min_samples_leaf,\n",
        "                  'bootstrap': bootstrap}\n",
        "\n",
        "    print('◆　Random Hypterparameter Grid')\n",
        "    pprint(random_grid)\n",
        "    print('')\n",
        "\n",
        "    # Use the random grid to search for best hyperparameters\n",
        "    # First create the base model to tune\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf = RandomForestClassifier()\n",
        "    # Random search of parameters, using 3 fold cross validation, \n",
        "    # search across 100 different combinations, and use all available cores\n",
        "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "    # Fit the random search model\n",
        "    rf_random.fit(variables, label)\n",
        "    print('')\n",
        "    print('◆　Best Parameters using RandomizedSearchCV')\n",
        "    pprint(rf_random.best_params_)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PQ-q8h0gA63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c5c82d89-340d-4fe3-dbe6-6995511545cf"
      },
      "source": [
        "RandomSearch(x, t)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "◆　Random Hypterparameter Grid\n",
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
            "\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   45.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "◆　Best Parameters using RandomizedSearchCV\n",
            "{'bootstrap': False,\n",
            " 'max_depth': 30,\n",
            " 'max_features': 'sqrt',\n",
            " 'min_samples_leaf': 4,\n",
            " 'min_samples_split': 5,\n",
            " 'n_estimators': 800}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQEK4rlqngIk",
        "colab_type": "text"
      },
      "source": [
        "#### B. GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRLFrmsghl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def GridSearch(variables, label):\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from pprint import pprint\n",
        "    # Create the parameter grid based on the results of random search \n",
        "    param_grid = {\n",
        "        'bootstrap': [True],\n",
        "        'max_depth': [20,30,40],\n",
        "        'max_features': ['sqrt'],\n",
        "        'min_samples_leaf': [1,2,3],\n",
        "        'min_samples_split': [4,5,6],\n",
        "        'n_estimators': [300,400,500]\n",
        "    }\n",
        "    # Create a based model\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf = RandomForestClassifier()\n",
        "    # Instantiate the grid search model\n",
        "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                              cv = 3, n_jobs = -1, verbose = 2)\n",
        "    # Fit the grid search to the data\n",
        "    grid_search.fit(variables, label)\n",
        "    print('')\n",
        "    print('◆　Best Parameters using GridSearchCV')\n",
        "    pprint(grid_search.best_params_)    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpOWLFnloQfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "056683b7-3696-47c4-be66-599ab227df01"
      },
      "source": [
        "GridSearch(x, t)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:  1.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "◆　Best Parameters using GridSearchCV\n",
            "{'bootstrap': True,\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 4,\n",
            " 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSgGsBApmvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomforest(random_state, bootstrap, max_depth, max_features, min_samples_leaf, min_samples_split, n_estimators):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state=random_state,\n",
        "                                bootstrap = True,\n",
        "                                max_depth = 20,\n",
        "                                max_features = 'sqrt',\n",
        "                                min_samples_leaf = 1,\n",
        "                                min_samples_split = 4,\n",
        "                                n_estimators = 300\n",
        "                                )\n",
        "  \n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/practice/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Random Forest')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    from pprint import pprint\n",
        "    print('◆ The settings of the hyperparameters')\n",
        "    pprint(rf.get_params())  \n",
        "    # n_estimators, max_features should be optimized first\n",
        "    # then, max_depth, min_sample_split, min_samples_leaf, bootstrap\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERzGt433veK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "21f88b1f-f893-4f3f-af38-e03331f5ed19"
      },
      "source": [
        "randomforest(41, True, 20, 'sqrt', 1, 4, 300)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.53295   Accuracy: 0.78431   R2: -0.275\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             1\n",
            "Predict False           10            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n",
            "◆ The settings of the hyperparameters\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 4,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 300,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 41,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5329545454545453, 0.7843137254901961, 0.5, 0.09090909090909091,\n",
              "       0.15384615384615385, 0.975, list([[1, 1], [10, 39]]),\n",
              "       -0.27500000000000036], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNcNheedzcj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "55d24dfc-5600-44e2-f2d2-df0fd403dea7"
      },
      "source": [
        "randomforest(625, False, 20, 'sqrt', 1, 4, 300)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.53295   Accuracy: 0.78431   R2: -0.275\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             1\n",
            "Predict False           10            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n",
            "◆ The settings of the hyperparameters\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 4,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 300,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 625,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5329545454545453, 0.7843137254901961, 0.5, 0.09090909090909091,\n",
              "       0.15384615384615385, 0.975, list([[1, 1], [10, 39]]),\n",
              "       -0.27500000000000036], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g110jeBzTtRz",
        "colab_type": "text"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTUzS_FYTQhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomFOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import optuna\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    random_state = trial.suggest_int('random_state', 1, 2000)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state = random_state)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # minimize 1/AUC\n",
        "    return 1/auc\n",
        "\n",
        "\n",
        "def randomFTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(randomFOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hyperparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)\n",
        "    print()\n",
        "    return study.best_params['random_state']    "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Q-qw2-n6SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "665b5263-01c9-4dd4-89dc-56e0f4fb1a74"
      },
      "source": [
        "randomFTrial(100)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-09-19 15:37:06,041] A new study created in memory with name: no-name-09782be3-9633-48e3-b32d-8f05601f4e45\n",
            "[I 2020-09-19 15:37:13,276] Trial 0 finished with value: 1.8763326226012798 and parameters: {'random_state': 739}. Best is trial 0 with value: 1.8763326226012798.\n",
            "[I 2020-09-19 15:37:20,449] Trial 1 finished with value: 1.8763326226012798 and parameters: {'random_state': 32}. Best is trial 0 with value: 1.8763326226012798.\n",
            "[I 2020-09-19 15:37:27,634] Trial 2 finished with value: 1.8763326226012798 and parameters: {'random_state': 1593}. Best is trial 0 with value: 1.8763326226012798.\n",
            "[I 2020-09-19 15:37:34,823] Trial 3 finished with value: 1.8763326226012798 and parameters: {'random_state': 1318}. Best is trial 0 with value: 1.8763326226012798.\n",
            "[I 2020-09-19 15:37:42,068] Trial 4 finished with value: 1.8333333333333335 and parameters: {'random_state': 1883}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:37:49,290] Trial 5 finished with value: 1.8763326226012798 and parameters: {'random_state': 1377}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:37:56,516] Trial 6 finished with value: 1.8333333333333335 and parameters: {'random_state': 1014}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:03,725] Trial 7 finished with value: 1.8763326226012798 and parameters: {'random_state': 633}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:10,917] Trial 8 finished with value: 1.8763326226012798 and parameters: {'random_state': 540}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:18,180] Trial 9 finished with value: 1.8763326226012798 and parameters: {'random_state': 1303}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:25,402] Trial 10 finished with value: 1.8333333333333335 and parameters: {'random_state': 1932}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:32,573] Trial 11 finished with value: 1.8763326226012798 and parameters: {'random_state': 1958}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:39,803] Trial 12 finished with value: 1.8763326226012798 and parameters: {'random_state': 24}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:47,030] Trial 13 finished with value: 1.8763326226012798 and parameters: {'random_state': 946}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:38:54,227] Trial 14 finished with value: 1.8763326226012798 and parameters: {'random_state': 273}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:01,410] Trial 15 finished with value: 1.8763326226012798 and parameters: {'random_state': 1691}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:08,482] Trial 16 finished with value: 2.0 and parameters: {'random_state': 1073}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:15,626] Trial 17 finished with value: 1.8763326226012798 and parameters: {'random_state': 1771}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:22,746] Trial 18 finished with value: 1.8763326226012798 and parameters: {'random_state': 1006}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:29,974] Trial 19 finished with value: 2.0512820512820515 and parameters: {'random_state': 349}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:37,103] Trial 20 finished with value: 1.8333333333333335 and parameters: {'random_state': 1490}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:44,239] Trial 21 finished with value: 1.8763326226012798 and parameters: {'random_state': 1985}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:51,386] Trial 22 finished with value: 1.8763326226012798 and parameters: {'random_state': 1881}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:39:58,488] Trial 23 finished with value: 1.8763326226012798 and parameters: {'random_state': 1521}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:05,690] Trial 24 finished with value: 2.0 and parameters: {'random_state': 1183}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:12,921] Trial 25 finished with value: 1.8333333333333335 and parameters: {'random_state': 845}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:20,070] Trial 26 finished with value: 1.8763326226012798 and parameters: {'random_state': 1514}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:27,254] Trial 27 finished with value: 1.8763326226012798 and parameters: {'random_state': 1745}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:34,351] Trial 28 finished with value: 2.0512820512820515 and parameters: {'random_state': 860}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:41,560] Trial 29 finished with value: 1.8333333333333335 and parameters: {'random_state': 799}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:48,628] Trial 30 finished with value: 1.8763326226012798 and parameters: {'random_state': 744}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:40:55,705] Trial 31 finished with value: 1.8763326226012798 and parameters: {'random_state': 1140}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:02,878] Trial 32 finished with value: 1.8333333333333335 and parameters: {'random_state': 839}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:09,989] Trial 33 finished with value: 2.0512820512820515 and parameters: {'random_state': 527}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:17,073] Trial 34 finished with value: 1.8763326226012798 and parameters: {'random_state': 267}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:24,182] Trial 35 finished with value: 1.8763326226012798 and parameters: {'random_state': 717}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:31,240] Trial 36 finished with value: 1.8763326226012798 and parameters: {'random_state': 1252}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:38,557] Trial 37 finished with value: 1.8763326226012798 and parameters: {'random_state': 580}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:46,176] Trial 38 finished with value: 1.8763326226012798 and parameters: {'random_state': 883}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:41:53,277] Trial 39 finished with value: 1.8763326226012798 and parameters: {'random_state': 688}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:00,440] Trial 40 finished with value: 1.921397379912664 and parameters: {'random_state': 1487}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:07,598] Trial 41 finished with value: 1.8763326226012798 and parameters: {'random_state': 1391}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:15,341] Trial 42 finished with value: 1.8763326226012798 and parameters: {'random_state': 1069}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:23,064] Trial 43 finished with value: 1.8763326226012798 and parameters: {'random_state': 810}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:31,028] Trial 44 finished with value: 1.8763326226012798 and parameters: {'random_state': 451}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:38,229] Trial 45 finished with value: 1.8763326226012798 and parameters: {'random_state': 967}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:45,405] Trial 46 finished with value: 1.8333333333333335 and parameters: {'random_state': 1878}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:52,444] Trial 47 finished with value: 1.8333333333333335 and parameters: {'random_state': 1840}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:42:59,525] Trial 48 finished with value: 1.8763326226012798 and parameters: {'random_state': 809}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:06,679] Trial 49 finished with value: 1.8763326226012798 and parameters: {'random_state': 1822}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:13,773] Trial 50 finished with value: 1.8763326226012798 and parameters: {'random_state': 1672}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:20,887] Trial 51 finished with value: 1.8763326226012798 and parameters: {'random_state': 1846}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:28,095] Trial 52 finished with value: 1.8763326226012798 and parameters: {'random_state': 1992}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:35,187] Trial 53 finished with value: 1.8333333333333335 and parameters: {'random_state': 1634}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:42,238] Trial 54 finished with value: 1.8763326226012798 and parameters: {'random_state': 1629}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:49,269] Trial 55 finished with value: 2.0512820512820515 and parameters: {'random_state': 1421}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:43:56,367] Trial 56 finished with value: 1.8763326226012798 and parameters: {'random_state': 629}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:03,453] Trial 57 finished with value: 1.8763326226012798 and parameters: {'random_state': 913}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:10,614] Trial 58 finished with value: 1.8333333333333335 and parameters: {'random_state': 1057}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:17,692] Trial 59 finished with value: 1.8763326226012798 and parameters: {'random_state': 784}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:24,782] Trial 60 finished with value: 1.8763326226012798 and parameters: {'random_state': 1724}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:31,823] Trial 61 finished with value: 1.8763326226012798 and parameters: {'random_state': 1931}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:38,869] Trial 62 finished with value: 1.8763326226012798 and parameters: {'random_state': 1590}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:45,969] Trial 63 finished with value: 1.8763326226012798 and parameters: {'random_state': 1920}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:44:53,025] Trial 64 finished with value: 1.8763326226012798 and parameters: {'random_state': 1769}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:00,114] Trial 65 finished with value: 1.8333333333333335 and parameters: {'random_state': 1307}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:07,238] Trial 66 finished with value: 2.0 and parameters: {'random_state': 1038}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:14,320] Trial 67 finished with value: 1.8763326226012798 and parameters: {'random_state': 1306}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:21,516] Trial 68 finished with value: 2.0512820512820515 and parameters: {'random_state': 1802}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:28,739] Trial 69 finished with value: 1.8763326226012798 and parameters: {'random_state': 1889}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:35,908] Trial 70 finished with value: 1.8333333333333335 and parameters: {'random_state': 1981}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:43,046] Trial 71 finished with value: 1.8763326226012798 and parameters: {'random_state': 1968}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:50,188] Trial 72 finished with value: 1.8763326226012798 and parameters: {'random_state': 1148}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:45:57,361] Trial 73 finished with value: 1.8763326226012798 and parameters: {'random_state': 671}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:04,556] Trial 74 finished with value: 1.8763326226012798 and parameters: {'random_state': 1234}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:11,683] Trial 75 finished with value: 1.8333333333333335 and parameters: {'random_state': 1465}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:18,787] Trial 76 finished with value: 1.8763326226012798 and parameters: {'random_state': 1431}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:26,011] Trial 77 finished with value: 1.8333333333333335 and parameters: {'random_state': 1543}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:33,156] Trial 78 finished with value: 1.8333333333333335 and parameters: {'random_state': 1559}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:40,365] Trial 79 finished with value: 1.8763326226012798 and parameters: {'random_state': 939}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:47,635] Trial 80 finished with value: 1.8763326226012798 and parameters: {'random_state': 1370}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:46:55,360] Trial 81 finished with value: 1.8333333333333335 and parameters: {'random_state': 1110}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:02,563] Trial 82 finished with value: 1.8333333333333335 and parameters: {'random_state': 1101}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:09,699] Trial 83 finished with value: 1.8763326226012798 and parameters: {'random_state': 1104}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:16,882] Trial 84 finished with value: 1.8333333333333335 and parameters: {'random_state': 847}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:24,191] Trial 85 finished with value: 1.8763326226012798 and parameters: {'random_state': 832}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:31,366] Trial 86 finished with value: 1.8333333333333335 and parameters: {'random_state': 1233}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:39,197] Trial 87 finished with value: 1.8333333333333335 and parameters: {'random_state': 1003}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:47,248] Trial 88 finished with value: 1.921397379912664 and parameters: {'random_state': 985}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:47:55,474] Trial 89 finished with value: 1.8763326226012798 and parameters: {'random_state': 1676}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:02,831] Trial 90 finished with value: 1.8763326226012798 and parameters: {'random_state': 1463}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:10,111] Trial 91 finished with value: 1.8763326226012798 and parameters: {'random_state': 1612}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:17,360] Trial 92 finished with value: 1.8763326226012798 and parameters: {'random_state': 1331}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:24,432] Trial 93 finished with value: 1.8333333333333335 and parameters: {'random_state': 907}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:31,621] Trial 94 finished with value: 1.8763326226012798 and parameters: {'random_state': 1525}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:38,824] Trial 95 finished with value: 1.8763326226012798 and parameters: {'random_state': 762}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:46,117] Trial 96 finished with value: 1.8763326226012798 and parameters: {'random_state': 1555}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:48:53,276] Trial 97 finished with value: 1.8333333333333335 and parameters: {'random_state': 1276}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:49:00,544] Trial 98 finished with value: 1.8333333333333335 and parameters: {'random_state': 1278}. Best is trial 4 with value: 1.8333333333333335.\n",
            "[I 2020-09-19 15:49:07,684] Trial 99 finished with value: 1.921397379912664 and parameters: {'random_state': 1272}. Best is trial 4 with value: 1.8333333333333335.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyperparameter： {'random_state': 1883}\n",
            "AUC： 0.5454545454545454\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQjSaZD6DiMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "edee75ef-1ecd-4d98-a243-e4efa0df3e7c"
      },
      "source": [
        "# This random_state value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "randomF(1883)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.54545   Accuracy: 0.80392   R2: -0.15909\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             0\n",
            "Predict False           10            40\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5454545454545454, 0.803921568627451, 1.0, 0.09090909090909091,\n",
              "       0.16666666666666666, 1.0, list([[1, 0], [10, 40]]),\n",
              "       -0.1590909090909094], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJD4d2FnG3G-",
        "colab_type": "text"
      },
      "source": [
        "## 7) XGBoost ; AUC 0.668"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9AwzxeuiBdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xgboost(eta):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import xgboost as xgb\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    round = []\n",
        "    pred = []\n",
        "    pairs = []\n",
        "    \n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "\n",
        "\n",
        "    # Hypter-parameter settings\n",
        "    params = {\n",
        "        'objective' : 'binary:logistic',\n",
        "        'silent' : 0,\n",
        "        'eta' : eta,\n",
        "        'random_state' : 71,\n",
        "        'max_depth' : 5,\n",
        "        'eval_metric' : 'logloss'\n",
        "    }\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        # transform data structure for XGBoost\n",
        "        d_train = xgb.DMatrix(x_train, label=t_train)\n",
        "        d_test = xgb.DMatrix(x_test, label=t_test)\n",
        "        # training\n",
        "        model = xgb.train(params, d_train)\n",
        "        result = model.predict(d_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)    \n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with XGBoost')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "\n",
        "    return res\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0t1AN_CXqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a6c8fbee-08b4-4df7-a872-6dc6ee9857ce"
      },
      "source": [
        "xgboost(0.1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.64091   Accuracy: 0.72549   R2: -0.03556\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             4\n",
            "Predict False           10            36\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.640909090909091, 0.7254901960784313, 0.2, 0.09090909090909091,\n",
              "       0.125, 0.9, list([[1, 4], [10, 36]]), -0.03556390450401259],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEL6MlDXilAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e11ae45f-48b0-413b-8ebc-9661e1166c97"
      },
      "source": [
        "xgboost(0.3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.57273   Accuracy: 0.76471   R2: -0.11337\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             2\n",
            "Predict False           10            38\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5727272727272728, 0.7647058823529411, 0.3333333333333333,\n",
              "       0.09090909090909091, 0.14285714285714285, 0.95,\n",
              "       list([[1, 2], [10, 38]]), -0.11337225409718865], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEqlptpCjTgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1f4994a9-54fa-4ed7-b9d2-1c32c41ea9d0"
      },
      "source": [
        "xgboost(0.2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.675   Accuracy: 0.78431   R2: 2e-05\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             1\n",
            "Predict False           10            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.675, 0.7843137254901961, 0.5, 0.09090909090909091,\n",
              "       0.15384615384615385, 0.975, list([[1, 1], [10, 39]]),\n",
              "       1.922716373370381e-05], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4_6uCw-ja8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6051b978-33a4-4867-a882-4a40632d8261"
      },
      "source": [
        "xgboost(0.911)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.59091   Accuracy: 0.76471   R2: -0.19333\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             2             3\n",
            "Predict False            9            37\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5909090909090908, 0.7647058823529411, 0.4, 0.18181818181818182,\n",
              "       0.25, 0.925, list([[2, 3], [9, 37]]), -0.1933297138660992],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMT5l1gnEnH",
        "colab_type": "text"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXLL3vROkSN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xgboostOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import xgboost as xgb\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    eta = trial.suggest_uniform('eta', 0, 1)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    round = []\n",
        "    pred = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "\n",
        "\n",
        "    # Hypter-parameter settings\n",
        "    params = {\n",
        "        'objective' : 'binary:logistic',\n",
        "        'silent' : 0,\n",
        "        'eta' : eta,\n",
        "        'random_state' : 71,\n",
        "        'max_depth' : 5,\n",
        "        'eval_metric' : 'logloss'\n",
        "    }\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        # transform data structure for XGBoost\n",
        "        d_train = xgb.DMatrix(x_train, label=t_train)\n",
        "        d_test = xgb.DMatrix(x_test, label=t_test)\n",
        "        # training\n",
        "        model = xgb.train(params, d_train)\n",
        "        result = model.predict(d_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1/AUC\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def xgboostTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(xgboostOptuna, n_trials)\n",
        "\n",
        "    # result\n",
        "    print()\n",
        "    print('hyperparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value) "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMdDN9cGX91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09e879c8-f912-42b9-dfb5-1ab42560d1a5"
      },
      "source": [
        "xgboostTrial(100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-09-19 16:02:42,740] A new study created in memory with name: no-name-3b31c3e0-d521-4348-acc5-9232931ea4a1\n",
            "[I 2020-09-19 16:02:43,339] Trial 0 finished with value: 1.71875 and parameters: {'eta': 0.6435127138634738}. Best is trial 0 with value: 1.71875.\n",
            "[I 2020-09-19 16:02:43,910] Trial 1 finished with value: 1.7120622568093389 and parameters: {'eta': 0.7680080428910264}. Best is trial 1 with value: 1.7120622568093389.\n",
            "[I 2020-09-19 16:02:44,519] Trial 2 finished with value: 1.7054263565891472 and parameters: {'eta': 0.470759986317866}. Best is trial 2 with value: 1.7054263565891472.\n",
            "[I 2020-09-19 16:02:45,035] Trial 3 finished with value: 1.6923076923076923 and parameters: {'eta': 0.947085175501552}. Best is trial 3 with value: 1.6923076923076923.\n",
            "[I 2020-09-19 16:02:45,599] Trial 4 finished with value: 1.5714285714285714 and parameters: {'eta': 0.9754406062384664}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:46,162] Trial 5 finished with value: 1.71875 and parameters: {'eta': 0.48424198743269964}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:46,769] Trial 6 finished with value: 1.8644067796610169 and parameters: {'eta': 0.3457042099424291}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:47,377] Trial 7 finished with value: 1.6923076923076925 and parameters: {'eta': 0.4041473283159833}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:47,944] Trial 8 finished with value: 1.7670682730923695 and parameters: {'eta': 0.6128525520570003}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:48,530] Trial 9 finished with value: 1.6988416988416988 and parameters: {'eta': 0.6079269350460001}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:49,061] Trial 10 finished with value: 1.8106995884773662 and parameters: {'eta': 0.043897044888114356}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:49,668] Trial 11 finished with value: 1.660377358490566 and parameters: {'eta': 0.9969024178313565}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:50,193] Trial 12 finished with value: 1.6666666666666667 and parameters: {'eta': 0.9240076352074904}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:50,751] Trial 13 finished with value: 1.7254901960784312 and parameters: {'eta': 0.9425076962143007}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:51,298] Trial 14 finished with value: 1.685823754789272 and parameters: {'eta': 0.8024614110648411}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:51,912] Trial 15 finished with value: 1.6296296296296295 and parameters: {'eta': 0.17622809214813184}. Best is trial 4 with value: 1.5714285714285714.\n",
            "[I 2020-09-19 16:02:52,543] Trial 16 finished with value: 1.5277777777777777 and parameters: {'eta': 0.19596908718161754}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:53,126] Trial 17 finished with value: 1.588447653429603 and parameters: {'eta': 0.2298077021948576}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:53,746] Trial 18 finished with value: 1.7813765182186236 and parameters: {'eta': 0.0766311695391203}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:54,339] Trial 19 finished with value: 1.6176470588235294 and parameters: {'eta': 0.2683856867311064}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:54,939] Trial 20 finished with value: 1.611721611721612 and parameters: {'eta': 0.13566679907715207}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:55,555] Trial 21 finished with value: 1.5942028985507246 and parameters: {'eta': 0.28451456019554233}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:56,150] Trial 22 finished with value: 1.7054263565891474 and parameters: {'eta': 0.2174442610115866}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:56,754] Trial 23 finished with value: 2.7160493827160495 and parameters: {'eta': 0.004700297186714747}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:57,348] Trial 24 finished with value: 1.795918367346939 and parameters: {'eta': 0.33671032132619144}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:57,973] Trial 25 finished with value: 1.6417910447761193 and parameters: {'eta': 0.17104163358196828}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:58,597] Trial 26 finished with value: 1.6793893129770991 and parameters: {'eta': 0.09271237323564291}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:59,174] Trial 27 finished with value: 1.6296296296296295 and parameters: {'eta': 0.37592495285022093}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:02:59,789] Trial 28 finished with value: 1.6479400749063668 and parameters: {'eta': 0.26569100395152045}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:00,384] Trial 29 finished with value: 1.5658362989323846 and parameters: {'eta': 0.5602150874689004}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:00,947] Trial 30 finished with value: 2.135922330097087 and parameters: {'eta': 0.7072352985876562}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:01,523] Trial 31 finished with value: 1.7120622568093384 and parameters: {'eta': 0.5491368764406567}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:02,060] Trial 32 finished with value: 1.746031746031746 and parameters: {'eta': 0.827616686856238}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:02,650] Trial 33 finished with value: 2.0183486238532113 and parameters: {'eta': 0.6897062207460923}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:03,235] Trial 34 finished with value: 1.660377358490566 and parameters: {'eta': 0.42328825316551477}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:03,833] Trial 35 finished with value: 1.6176470588235294 and parameters: {'eta': 0.5136483356897427}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:04,449] Trial 36 finished with value: 1.6176470588235294 and parameters: {'eta': 0.22108204130250017}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:05,020] Trial 37 finished with value: 2.6506024096385543 and parameters: {'eta': 0.0010761236465836044}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:05,567] Trial 38 finished with value: 1.8106995884773662 and parameters: {'eta': 0.8724480936348354}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:06,178] Trial 39 finished with value: 1.6417910447761197 and parameters: {'eta': 0.31576129266829}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:06,756] Trial 40 finished with value: 1.9047619047619047 and parameters: {'eta': 0.7369197608341385}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:07,340] Trial 41 finished with value: 1.660377358490566 and parameters: {'eta': 0.2889277863469429}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:07,925] Trial 42 finished with value: 1.6417910447761197 and parameters: {'eta': 0.43461237784869705}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:08,551] Trial 43 finished with value: 1.7054263565891474 and parameters: {'eta': 0.2159636569318746}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:09,160] Trial 44 finished with value: 1.6236162361623614 and parameters: {'eta': 0.1299263810994002}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:09,805] Trial 45 finished with value: 1.6296296296296295 and parameters: {'eta': 0.17195603079502844}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:10,428] Trial 46 finished with value: 1.7054263565891472 and parameters: {'eta': 0.5712622217080006}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:11,026] Trial 47 finished with value: 1.7670682730923697 and parameters: {'eta': 0.38034098249027837}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:11,624] Trial 48 finished with value: 1.7120622568093384 and parameters: {'eta': 0.46955100027677277}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:12,225] Trial 49 finished with value: 1.685823754789272 and parameters: {'eta': 0.24803144298245067}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:12,776] Trial 50 finished with value: 1.6541353383458648 and parameters: {'eta': 0.9885058054950668}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:13,370] Trial 51 finished with value: 1.673003802281369 and parameters: {'eta': 0.11746035302069932}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:13,958] Trial 52 finished with value: 1.8181818181818181 and parameters: {'eta': 0.06567260546896672}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:14,566] Trial 53 finished with value: 1.6858237547892718 and parameters: {'eta': 0.12512970356336844}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:15,165] Trial 54 finished with value: 1.746031746031746 and parameters: {'eta': 0.3092636769484737}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:15,720] Trial 55 finished with value: 2.0276497695852536 and parameters: {'eta': 0.0251338381865035}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:16,354] Trial 56 finished with value: 1.7391304347826089 and parameters: {'eta': 0.15342516890309912}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:16,995] Trial 57 finished with value: 1.5827338129496402 and parameters: {'eta': 0.20725068111734776}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:17,593] Trial 58 finished with value: 1.588447653429603 and parameters: {'eta': 0.19456891776525698}. Best is trial 16 with value: 1.5277777777777777.\n",
            "[I 2020-09-19 16:03:18,184] Trial 59 finished with value: 1.522491349480969 and parameters: {'eta': 0.19876448027921312}. Best is trial 59 with value: 1.522491349480969.\n",
            "[I 2020-09-19 16:03:18,808] Trial 60 finished with value: 1.71875 and parameters: {'eta': 0.21584168485267735}. Best is trial 59 with value: 1.522491349480969.\n",
            "[I 2020-09-19 16:03:19,417] Trial 61 finished with value: 1.5017064846416384 and parameters: {'eta': 0.19882553849367446}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:20,019] Trial 62 finished with value: 1.6923076923076925 and parameters: {'eta': 0.24867867703339938}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:20,682] Trial 63 finished with value: 1.7054263565891474 and parameters: {'eta': 0.18590623819553004}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:21,314] Trial 64 finished with value: 1.752988047808765 and parameters: {'eta': 0.09081318076244645}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:21,926] Trial 65 finished with value: 1.6923076923076925 and parameters: {'eta': 0.18849041048317017}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:22,526] Trial 66 finished with value: 1.6988416988416988 and parameters: {'eta': 0.364433758825625}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:23,080] Trial 67 finished with value: 1.8410041841004183 and parameters: {'eta': 0.6554321193512281}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:23,660] Trial 68 finished with value: 1.71875 and parameters: {'eta': 0.3350255027725738}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:24,261] Trial 69 finished with value: 1.6858237547892718 and parameters: {'eta': 0.24849195802485483}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:24,864] Trial 70 finished with value: 1.774193548387097 and parameters: {'eta': 0.05477315212261136}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:25,489] Trial 71 finished with value: 1.5770609318996418 and parameters: {'eta': 0.20577492349761892}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:26,108] Trial 72 finished with value: 1.7322834645669294 and parameters: {'eta': 0.14900454011220698}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:26,728] Trial 73 finished with value: 1.660377358490566 and parameters: {'eta': 0.2890306903234272}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:27,329] Trial 74 finished with value: 1.752988047808765 and parameters: {'eta': 0.10931339277655552}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:27,926] Trial 75 finished with value: 1.5017064846416384 and parameters: {'eta': 0.1989257328822957}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:28,560] Trial 76 finished with value: 1.71875 and parameters: {'eta': 0.15320893357652007}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:29,167] Trial 77 finished with value: 1.5120274914089347 and parameters: {'eta': 0.19632357029568903}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:29,770] Trial 78 finished with value: 1.7054263565891472 and parameters: {'eta': 0.26027840494274784}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:30,308] Trial 79 finished with value: 1.7959183673469385 and parameters: {'eta': 0.8922903373197147}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:30,868] Trial 80 finished with value: 1.7670682730923695 and parameters: {'eta': 0.034745634348070986}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:31,512] Trial 81 finished with value: 1.605839416058394 and parameters: {'eta': 0.2097998061167708}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:32,109] Trial 82 finished with value: 1.6356877323420076 and parameters: {'eta': 0.17492299388009847}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:32,721] Trial 83 finished with value: 1.6666666666666667 and parameters: {'eta': 0.27998086902105107}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:33,322] Trial 84 finished with value: 1.6923076923076925 and parameters: {'eta': 0.09620875676736138}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:33,914] Trial 85 finished with value: 1.7054263565891472 and parameters: {'eta': 0.2416812187670549}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:34,523] Trial 86 finished with value: 1.7599999999999998 and parameters: {'eta': 0.3081232019762159}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:35,113] Trial 87 finished with value: 1.533101045296167 and parameters: {'eta': 0.2012762837254132}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:35,725] Trial 88 finished with value: 1.6923076923076925 and parameters: {'eta': 0.15819345837402388}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:36,317] Trial 89 finished with value: 1.6 and parameters: {'eta': 0.23016211851086163}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:36,879] Trial 90 finished with value: 1.6541353383458648 and parameters: {'eta': 0.7745205564938219}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:37,494] Trial 91 finished with value: 1.5827338129496404 and parameters: {'eta': 0.1944985403844865}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:38,099] Trial 92 finished with value: 1.6793893129770991 and parameters: {'eta': 0.13630814951821735}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:38,746] Trial 93 finished with value: 1.7529880478087654 and parameters: {'eta': 0.2124868304252281}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:39,355] Trial 94 finished with value: 1.6541353383458648 and parameters: {'eta': 0.27369183208564674}. Best is trial 61 with value: 1.5017064846416384.\n",
            "[I 2020-09-19 16:03:39,965] Trial 95 finished with value: 1.4965986394557822 and parameters: {'eta': 0.1990049866560162}. Best is trial 95 with value: 1.4965986394557822.\n",
            "[I 2020-09-19 16:03:40,570] Trial 96 finished with value: 1.588447653429603 and parameters: {'eta': 0.23373469134394087}. Best is trial 95 with value: 1.4965986394557822.\n",
            "[I 2020-09-19 16:03:41,155] Trial 97 finished with value: 1.6479400749063673 and parameters: {'eta': 0.16786274366854875}. Best is trial 95 with value: 1.4965986394557822.\n",
            "[I 2020-09-19 16:03:41,821] Trial 98 finished with value: 1.6988416988416988 and parameters: {'eta': 0.11419051962570578}. Best is trial 95 with value: 1.4965986394557822.\n",
            "[I 2020-09-19 16:03:42,441] Trial 99 finished with value: 1.611721611721612 and parameters: {'eta': 0.135635053437839}. Best is trial 95 with value: 1.4965986394557822.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyperparameter： {'eta': 0.1990049866560162}\n",
            "AUC： 0.6681818181818182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZM2neJGHPIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9ac9a4fe-5d96-45cb-be7e-0af5bc8836d7"
      },
      "source": [
        "# This eta value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "xgboost(0.1990049866560162)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 51\n",
            "Sample size of training data: 50     Explanatory variables: (50, 211)   Target value: (50,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 211)   Target value: (1,)\n",
            "\n",
            "AUC: 0.66818   Accuracy: 0.78431   R2: 8e-05\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             1             1\n",
            "Predict False           10            39\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6681818181818182, 0.7843137254901961, 0.5, 0.09090909090909091,\n",
              "       0.15384615384615385, 0.975, list([[1, 1], [10, 39]]),\n",
              "       8.417951884320818e-05], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLwrb35HG5kG",
        "colab_type": "text"
      },
      "source": [
        "## 8) Symbolic Regression ; AUC 0.784"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRQDssWK39X",
        "colab_type": "text"
      },
      "source": [
        "#### See Leave-One-Out CV with renaldata by SR via GP.pdf file for the calculation processes of LOO with Symbolic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YGp_tZbra4o",
        "colab_type": "text"
      },
      "source": [
        "- Results of Leave-One-Out CV with SR via GP\n",
        "- AUC 0.784\n",
        "- Accuracy 82.35%\n",
        "- Precision 60.0%\n",
        "- Recall 54.55%\n",
        "- Sepcificity 90.0%\n",
        "- F1-measure 57.14\n",
        "- C-statistics 0.784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbqSJ3CbOsFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                 Actual True   Actual False\n",
        "Predicted True       6              4\n",
        "Predicted False      5             36 "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}